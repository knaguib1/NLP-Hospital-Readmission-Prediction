{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please run this notebook in google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMVSSmKo8BUr"
   },
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTCuu9BDs-XJ",
    "outputId": "37c3788b-0cb6-4984-8c2b-56733b156621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoTKcYU8s_0t",
    "outputId": "5bc8e83e-1dbe-4acd-ecfa-853e107c6c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/cse6250\n"
     ]
    }
   ],
   "source": [
    "% cd //content/drive/MyDrive/cse6250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohAurDUZs_3W",
    "outputId": "fe4555c7-5624-41c4-e628-0d681f55ec5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated\n",
      "env: GCLOUD_PROJECT=project_id\n"
     ]
    }
   ],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "print('Authenticated')\n",
    "\n",
    "%load_ext google.colab.data_table\n",
    "# GCP proejct\n",
    "project_id = 'nlp-332020'\n",
    "project_number = '1054321893028'\n",
    "\n",
    "%env GCLOUD_PROJECT=project_id\n",
    "# authenticate colab notebook\n",
    "import sys\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CyC3o8RDtAW1",
    "outputId": "92e11058-f9a8-4b8f-b187-856068793b65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "It_2fY0Buvxl",
    "outputId": "0b30926d-d59d-411b-c3ca-54b71c4f5044"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://4294bb3dcaf6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Readmit</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ffb5347eed0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql import SQLContext\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"Readmit\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "base = \"/content/drive/My Drive/cse6250\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIz2m_eR8KnB"
   },
   "source": [
    "## ETL, text clean and data balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwLIvrWZu7Yo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import etl, utils  # code doing ETL and text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LKv6pohB9Hl"
   },
   "outputs": [],
   "source": [
    "psc = etl.readmission_etl(spark, client, nDays=30, s=11000)\n",
    "etl.save_sparkDF(spark, psc, 30)\n",
    "# psc = sqlContext.read.parquet( os.path.join(base,\"readmit_30.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HMko1jjvJOB"
   },
   "outputs": [],
   "source": [
    "psc.groupBy('LABEL').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K70GsMX0ulzO"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "psc.withColumn('length', length(psc['TEXT'])).select('LABEL','length').groupBy('LABEL').agg(F.min('length'), F.max('length'), F.mean('length') ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_sfaV_rCJDU"
   },
   "outputs": [],
   "source": [
    "df = utils.segment_text(spark, sqlContext, psc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M40bJrUDCMuA"
   },
   "outputs": [],
   "source": [
    "# balance the data\n",
    "df_train, df_val, df_test = utils.class_balance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ob_7olmdCdVR"
   },
   "outputs": [],
   "source": [
    "base = \"/content/drive/MyDrive/cse6250/\"\n",
    "path = 'readmit_30days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bz0HjkvaCpp1"
   },
   "outputs": [],
   "source": [
    "# save data for modeling\n",
    "utils.save_data(df_train, path, 'train.csv')\n",
    "utils.save_data(df_test, path, 'test.csv')\n",
    "utils.save_data(df_val, path, 'val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqeaNZqpxJNT"
   },
   "source": [
    "## Modeling with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0btCbCb61pM"
   },
   "source": [
    "### Read in csv file to spark dataframe for modeling with pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aweDY3KOxMQ-"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer, StringIndexer, VectorAssembler, StopWordsRemover, RegexTokenizer, Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator \n",
    "from pyspark.ml.tuning import CrossValidator,  TrainValidationSplit, ParamGridBuilder \n",
    "from pyspark.sql.functions import countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sU5aQfDf8Vvq"
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder \\\n",
    "#     .master(\"local[1]\") \\\n",
    "#     .appName(\"Readmit\") \\\n",
    "#     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJCmFPDmlGuJ"
   },
   "outputs": [],
   "source": [
    "base = \"/content/drive/MyDrive/cse6250/\"\n",
    "path = 'readmit_30'\n",
    "train_set = spark.read.csv(os.path.join(base, path, \"train.csv\"), inferSchema=True, header = True)\n",
    "val_set = spark.read.csv(os.path.join(base, path, \"val.csv\"), inferSchema=True, header = True)\n",
    "test_set = spark.read.csv(os.path.join(base, path, \"test.csv\"), inferSchema=True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0sxA7qqxMa7",
    "outputId": "beffe7fb-f53d-4d4f-ed0c-16123c64b918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Label: integer (nullable = true)\n",
      " |-- TEXT: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TO7YLlGsx8Dd",
    "outputId": "5bee4440-1768-4329-bb22-6f9c3688689d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT Label)|\n",
      "+---------------------+\n",
      "|                    2|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set.select(countDistinct(\"Label\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_YHTzK-4lCy"
   },
   "source": [
    "### Build classification models on TF-IDF tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hg1XS0E1xMdi"
   },
   "outputs": [],
   "source": [
    "# get tf-idf tokens\n",
    "# ref: https://github.com/adarsh-tyagi/Apache-Spark-ML/blob/master/NLP_Code_Along.ipynb\n",
    "tokenizer = Tokenizer(inputCol=\"TEXT\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='words')\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"words\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "tokenPipeline = Pipeline(stages = [tokenizer, stopremove, cv, idf])\n",
    "token = tokenPipeline.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i1N0YjcF8Mx"
   },
   "source": [
    "#### Define functions to do prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TsOEH5W_BX7"
   },
   "outputs": [],
   "source": [
    "def get_pred(token, labelcol, classifier, train_set, val_set, test_set ):\n",
    "  label_stringIdx = StringIndexer(inputCol = labelcol, outputCol = \"label\")\n",
    "  pipeline = Pipeline(stages=[token, label_stringIdx, classifier])\n",
    "  model = pipeline.fit(train_set)\n",
    "  tr_df = model.transform(train_set)\n",
    "  val_df = model.transform(val_set)\n",
    "  te_df = model.transform(test_set)\n",
    "  # print(te_df.groupBy('label', 'prediction').count().show())\n",
    "  print('train set metric')\n",
    "  get_metric(tr_df)\n",
    "  print('val set metric')\n",
    "  get_metric(val_df)\n",
    "  print('test set metric')\n",
    "  get_metric(te_df)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jiBpOtHcxKlq"
   },
   "outputs": [],
   "source": [
    "eva  = BinaryClassificationEvaluator()\n",
    "# ref: https://shihaojran.com/distributed-machine-learning-using-pyspark/\n",
    "def get_metric(predictions):\n",
    "  # calculate AUC\n",
    "  auc = eva.evaluate(predictions, {eva.metricName: 'areaUnderROC'})\n",
    "  print('AUROC: %0.3f' % auc)\n",
    "  aucpr = eva.evaluate(predictions, {eva.metricName: 'areaUnderPR'})\n",
    "  print('AUCPR: %0.3f' % aucpr)\n",
    "  # compute TN, TP, FN, and FP\n",
    "  predictions.groupBy('label', 'prediction').count().show()\n",
    "  # Calculate the elements of the confusion matrix\n",
    "  TN = predictions.filter('prediction = 0 AND label = prediction').count()\n",
    "  TP = predictions.filter('prediction = 1 AND label = prediction').count()\n",
    "  FN = predictions.filter('prediction = 0 AND label <> prediction').count()\n",
    "  FP = predictions.filter('prediction = 1 AND label <> prediction').count()\n",
    "  # calculate accuracy, precision, recall, and F1-score\n",
    "  accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "  precision = TP / (TP + FP)\n",
    "  recall = TP / (TP + FN)\n",
    "  F =  2 * (precision*recall) / (precision + recall)\n",
    "  print('precision: %0.3f' % precision)\n",
    "  print('recall: %0.3f' % recall)\n",
    "  print('accuracy: %0.3f' % accuracy)\n",
    "  print('F1 score: %0.3f' % F)\n",
    "  print('\\n')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "am29d1YSGE11"
   },
   "source": [
    "#### Apply logistic regression on TF-IDF tokens and use CV to do hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytuKP5SiCQl7",
    "outputId": "7cd16d2f-3346-464b-e659-e730c1bf838d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  902|\n",
      "|  0.0|       1.0|  556|\n",
      "|  1.0|       0.0|  674|\n",
      "|  0.0|       0.0|  876|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "start get metric\n",
      "AUROC: 0.783\n",
      "AUCPR: 0.778\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 8995|\n",
      "|  0.0|       1.0| 3607|\n",
      "|  1.0|       0.0| 3980|\n",
      "|  0.0|       0.0| 9494|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.714\n",
      "recall: 0.693\n",
      "accuracy: 0.709\n",
      "F1 score: 0.703\n",
      "AUROC: 0.607\n",
      "AUCPR: 0.613\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  836|\n",
      "|  0.0|       1.0|  545|\n",
      "|  1.0|       0.0|  720|\n",
      "|  0.0|       0.0|  848|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.605\n",
      "recall: 0.537\n",
      "accuracy: 0.571\n",
      "F1 score: 0.569\n",
      "AUROC: 0.613\n",
      "AUCPR: 0.619\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  902|\n",
      "|  0.0|       1.0|  556|\n",
      "|  1.0|       0.0|  674|\n",
      "|  0.0|       0.0|  876|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.619\n",
      "recall: 0.572\n",
      "accuracy: 0.591\n",
      "F1 score: 0.595\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=20)\n",
    "lr.setRegParam(0.0001)\n",
    "get_pred(token, 'Label', lr, train_set, val_set, test_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flrJTt7CIwak"
   },
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"Label\", outputCol = \"label\")\n",
    "lr = LogisticRegression()\n",
    "params = ParamGridBuilder()\n",
    "params = params.addGrid(lr.regParam, [1e-5, 0.00005, .0001, .0005, 0.001, 0.005, 0.01]).addGrid(lr.maxIter, [10, 20]).addGrid(lr.elasticNetParam, [0, .5, 1])\n",
    "          #.0005, 0.001, 0.005, 0.01]) \n",
    "params = params.build()\n",
    "\n",
    "f1eva = MulticlassClassificationEvaluator(metricName='fMeasureByLabel', metricLabel=1, beta=1.0) \n",
    "pipeline = Pipeline(stages = [token, label_stringIdx, lr])\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "                    estimatorParamMaps=params,\n",
    "                    evaluator= f1eva,\n",
    "                    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaVhhNKdm82U",
    "outputId": "6901ba28-4ea5-4c39-f33e-98ab5c4cc415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5964678440519826"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1eva.evaluate(cvModel.transform(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQgsoZErKYVF"
   },
   "outputs": [],
   "source": [
    "cvModel = cv.fit(train_set)\n",
    "bestModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-2yEc9fhCIH",
    "outputId": "55f9d91b-52ef-4259-fc53-f296b3611d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.617183798744118\n"
     ]
    }
   ],
   "source": [
    "print(cvModel.avgMetrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bjvQq2hZe1w"
   },
   "outputs": [],
   "source": [
    "# model_path = os.path.join(base + \"LGmodel_cv\")\n",
    "# cvModel.write().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mD89KQxFhfuq",
    "outputId": "3edc29d6-beb7-4643-e0cc-7bd1f6d240d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.630\n",
      "AUCPR: 0.629\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  895|\n",
      "|  0.0|       1.0|  530|\n",
      "|  1.0|       0.0|  681|\n",
      "|  0.0|       0.0|  902|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.628\n",
      "recall: 0.568\n",
      "accuracy: 0.597\n",
      "F1 score: 0.596\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = bestModel.transform(test_set)\n",
    "get_metric(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nI4ZSb_zLy8w",
    "outputId": "df2e91e6-918c-49dc-9796-2d843afa8e23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_49cc9e0386f5', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5,\n",
       " Param(parent='LogisticRegression_49cc9e0386f5', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       " Param(parent='LogisticRegression_49cc9e0386f5', name='regParam', doc='regularization parameter (>= 0).'): 0.005}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get best param\n",
    "cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]\n",
    "# 0.628637\treg0.00500\titer10\telesticNetParam0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "t5AnWpaKLpiw",
    "outputId": "d32e09a5-57e2-4704-d56b-b549e7591629"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fMeasureByLabel</th>\n",
       "      <th>regParam</th>\n",
       "      <th>maxIter</th>\n",
       "      <th>elasticNetParam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.617184</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.616692</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616972</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611275</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.606526</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.606890</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.617413</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.616781</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.616795</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.612459</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.606524</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.608337</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.617517</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.616310</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.617010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.612791</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.609309</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.610173</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.617838</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.619511</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.621911</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.614242</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.612147</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.612484</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.617739</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.622510</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.625504</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.613731</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.614147</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.617114</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.619888</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.628637</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.625510</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.612009</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.622769</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.626117</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.620683</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.625433</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.603364</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.611690</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.626519</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.603623</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fMeasureByLabel  regParam  maxIter  elasticNetParam\n",
       "0          0.617184   0.00001       10              0.0\n",
       "1          0.616692   0.00001       10              0.5\n",
       "2          0.616972   0.00001       10              1.0\n",
       "3          0.611275   0.00001       20              0.0\n",
       "4          0.606526   0.00001       20              0.5\n",
       "5          0.606890   0.00001       20              1.0\n",
       "6          0.617413   0.00005       10              0.0\n",
       "7          0.616781   0.00005       10              0.5\n",
       "8          0.616795   0.00005       10              1.0\n",
       "9          0.612459   0.00005       20              0.0\n",
       "10         0.606524   0.00005       20              0.5\n",
       "11         0.608337   0.00005       20              1.0\n",
       "12         0.617517   0.00010       10              0.0\n",
       "13         0.616310   0.00010       10              0.5\n",
       "14         0.617010   0.00010       10              1.0\n",
       "15         0.612791   0.00010       20              0.0\n",
       "16         0.609309   0.00010       20              0.5\n",
       "17         0.610173   0.00010       20              1.0\n",
       "18         0.617838   0.00050       10              0.0\n",
       "19         0.619511   0.00050       10              0.5\n",
       "20         0.621911   0.00050       10              1.0\n",
       "21         0.614242   0.00050       20              0.0\n",
       "22         0.612147   0.00050       20              0.5\n",
       "23         0.612484   0.00050       20              1.0\n",
       "24         0.617739   0.00100       10              0.0\n",
       "25         0.622510   0.00100       10              0.5\n",
       "26         0.625504   0.00100       10              1.0\n",
       "27         0.613731   0.00100       20              0.0\n",
       "28         0.614147   0.00100       20              0.5\n",
       "29         0.617114   0.00100       20              1.0\n",
       "30         0.619888   0.00500       10              0.0\n",
       "31         0.628637   0.00500       10              0.5\n",
       "32         0.625510   0.00500       10              1.0\n",
       "33         0.612009   0.00500       20              0.0\n",
       "34         0.622769   0.00500       20              0.5\n",
       "35         0.626117   0.00500       20              1.0\n",
       "36         0.620683   0.01000       10              0.0\n",
       "37         0.625433   0.01000       10              0.5\n",
       "38         0.603364   0.01000       10              1.0\n",
       "39         0.611690   0.01000       20              0.0\n",
       "40         0.626519   0.01000       20              0.5\n",
       "41         0.603623   0.01000       20              1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use code from https://stackoverflow.com/questions/51230726/extract-results-from-crossvalidator-with-paramgrid-in-pyspark\n",
    "params = [{p.name: v for p, v in m.items()} for m in cvModel.getEstimatorParamMaps()]\n",
    "pd.DataFrame.from_dict([\n",
    "    {cvModel.getEvaluator().getMetricName(): metric, **ps} \n",
    "    for ps, metric in zip(params, cvModel.avgMetrics)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VfDa-UuEw3m"
   },
   "source": [
    "#### Apply random forest on tf-idf tokens and tried different hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdiIRZAUEV-_",
    "outputId": "1727528b-cf6e-4aa3-bf7a-e4f5c136d1e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.902\n",
      "AUCPR: 0.911\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 9898|\n",
      "|  0.0|       1.0| 1643|\n",
      "|  1.0|       0.0| 3077|\n",
      "|  0.0|       0.0|11458|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.858\n",
      "recall: 0.763\n",
      "accuracy: 0.819\n",
      "F1 score: 0.807\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.638\n",
      "AUCPR: 0.638\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  854|\n",
      "|  0.0|       1.0|  519|\n",
      "|  1.0|       0.0|  702|\n",
      "|  0.0|       0.0|  874|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.622\n",
      "recall: 0.549\n",
      "accuracy: 0.586\n",
      "F1 score: 0.583\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.642\n",
      "AUCPR: 0.642\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  941|\n",
      "|  0.0|       1.0|  531|\n",
      "|  1.0|       0.0|  635|\n",
      "|  0.0|       0.0|  901|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.639\n",
      "recall: 0.597\n",
      "accuracy: 0.612\n",
      "F1 score: 0.617\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier( numTrees=100, maxDepth=20, subsamplingRate=0.88)\n",
    "get_pred(token, 'Label', rf, train_set, val_set, test_set ) #take 12mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ENS6gEY7-Erh",
    "outputId": "59d4d5e7-3531-4409-a039-30ff3ad3d7b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.905\n",
      "AUCPR: 0.914\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 9707|\n",
      "|  0.0|       1.0| 1390|\n",
      "|  1.0|       0.0| 3268|\n",
      "|  0.0|       0.0|11711|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.875\n",
      "recall: 0.748\n",
      "accuracy: 0.821\n",
      "F1 score: 0.806\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.621\n",
      "AUCPR: 0.625\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  838|\n",
      "|  0.0|       1.0|  500|\n",
      "|  1.0|       0.0|  718|\n",
      "|  0.0|       0.0|  893|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.626\n",
      "recall: 0.539\n",
      "accuracy: 0.587\n",
      "F1 score: 0.579\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.635\n",
      "AUCPR: 0.632\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  918|\n",
      "|  0.0|       1.0|  528|\n",
      "|  1.0|       0.0|  658|\n",
      "|  0.0|       0.0|  904|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.635\n",
      "recall: 0.582\n",
      "accuracy: 0.606\n",
      "F1 score: 0.608\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier( numTrees=100, maxDepth=20 )\n",
    "rf100 = get_pred(token, 'Label', rf, train_set, val_set, test_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KsMcQMhG-K9N",
    "outputId": "6b7c52ef-d6ab-4282-b17f-e1e865e597dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.975\n",
      "AUCPR: 0.978\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|11010|\n",
      "|  0.0|       1.0|  373|\n",
      "|  1.0|       0.0| 1965|\n",
      "|  0.0|       0.0|12728|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.967\n",
      "recall: 0.849\n",
      "accuracy: 0.910\n",
      "F1 score: 0.904\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.630\n",
      "AUCPR: 0.631\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  881|\n",
      "|  0.0|       1.0|  524|\n",
      "|  1.0|       0.0|  675|\n",
      "|  0.0|       0.0|  869|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.627\n",
      "recall: 0.566\n",
      "accuracy: 0.593\n",
      "F1 score: 0.595\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.639\n",
      "AUCPR: 0.636\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  963|\n",
      "|  0.0|       1.0|  556|\n",
      "|  1.0|       0.0|  613|\n",
      "|  0.0|       0.0|  876|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.634\n",
      "recall: 0.611\n",
      "accuracy: 0.611\n",
      "F1 score: 0.622\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier( numTrees=100, maxDepth=30 )\n",
    "rf100_30 = get_pred(token, 'Label', rf, train_set, val_set, test_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-ZzqUg4jQ3m",
    "outputId": "a0d0f788-e49f-4a29-d18f-aed586937781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.914\n",
      "AUCPR: 0.922\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 9875|\n",
      "|  0.0|       1.0| 1273|\n",
      "|  1.0|       0.0| 3100|\n",
      "|  0.0|       0.0|11828|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.886\n",
      "recall: 0.761\n",
      "accuracy: 0.832\n",
      "F1 score: 0.819\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.634\n",
      "AUCPR: 0.632\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  845|\n",
      "|  0.0|       1.0|  510|\n",
      "|  1.0|       0.0|  711|\n",
      "|  0.0|       0.0|  883|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.624\n",
      "recall: 0.543\n",
      "accuracy: 0.586\n",
      "F1 score: 0.581\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.646\n",
      "AUCPR: 0.642\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  912|\n",
      "|  0.0|       1.0|  529|\n",
      "|  1.0|       0.0|  664|\n",
      "|  0.0|       0.0|  903|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.633\n",
      "recall: 0.579\n",
      "accuracy: 0.603\n",
      "F1 score: 0.605\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier( numTrees=200, maxDepth=20 )\n",
    "rf200 = get_pred(token, 'Label', rf, train_set, val_set, test_set ) #take 12mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U-0QAjy5Aid"
   },
   "source": [
    "#### Also tried NaiveBayes and GBT but the performance is not good and GBT took long very time to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_1borV-SeXS",
    "outputId": "eaedbf3c-385c-42b6-c9d6-b42bf0ec6916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.490\n",
      "AUCPR: 0.485\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 9809|\n",
      "|  0.0|       1.0| 3444|\n",
      "|  1.0|       0.0| 3166|\n",
      "|  0.0|       0.0| 9657|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.740\n",
      "recall: 0.756\n",
      "accuracy: 0.747\n",
      "F1 score: 0.748\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.480\n",
      "AUCPR: 0.513\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  924|\n",
      "|  0.0|       1.0|  563|\n",
      "|  1.0|       0.0|  632|\n",
      "|  0.0|       0.0|  830|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.621\n",
      "recall: 0.594\n",
      "accuracy: 0.595\n",
      "F1 score: 0.607\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.504\n",
      "AUCPR: 0.516\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 1012|\n",
      "|  0.0|       1.0|  573|\n",
      "|  1.0|       0.0|  564|\n",
      "|  0.0|       0.0|  859|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.638\n",
      "recall: 0.642\n",
      "accuracy: 0.622\n",
      "F1 score: 0.640\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "nbmodel = get_pred(token, 'Label', nb, train_set, val_set, test_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eVpAcTKVtbY",
    "outputId": "15eeed98-8220-45bb-de0a-705525ebcdca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.905\n",
      "AUCPR: 0.911\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 9684|\n",
      "|  0.0|       1.0| 1560|\n",
      "|  1.0|       0.0| 3291|\n",
      "|  0.0|       0.0|11541|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.861\n",
      "recall: 0.746\n",
      "accuracy: 0.814\n",
      "F1 score: 0.800\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.564\n",
      "AUCPR: 0.572\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  778|\n",
      "|  0.0|       1.0|  537|\n",
      "|  1.0|       0.0|  778|\n",
      "|  0.0|       0.0|  856|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.592\n",
      "recall: 0.500\n",
      "accuracy: 0.554\n",
      "F1 score: 0.542\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.556\n",
      "AUCPR: 0.565\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  807|\n",
      "|  0.0|       1.0|  556|\n",
      "|  1.0|       0.0|  769|\n",
      "|  0.0|       0.0|  876|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.592\n",
      "recall: 0.512\n",
      "accuracy: 0.560\n",
      "F1 score: 0.549\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(maxIter=5, maxDepth=20,  seed=42, leafCol=\"leafId\")\n",
    "gbtmodel = get_pred(token, 'Label', gbt, train_set, val_set, test_set )\n",
    "# take 48min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFz50O8u5RKx"
   },
   "source": [
    "### Build classification models on word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UkVPYYUB-kG"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, StringIndexer, VectorAssembler, HashingTF, IDF, Word2Vec\n",
    "\n",
    "## build word2vec tokens \n",
    "regex_tokenizer = RegexTokenizer(pattern='\\\\W')\\\n",
    "                  .setInputCol(\"TEXT\")\\\n",
    "                  .setOutputCol(\"tokens\")\n",
    " \n",
    "extra_stopwords = ['the',  'and', 'to', 'of', 'was', 'with', 'a', 'on', 'mg', 'in', 'for', 'tablet', 'no', 'is', 'po', 'patient', 's', 'he', 'blood', 'at', 'daily', 'sig', 'or', 'as', 'one',\n",
    " 'she', 'day', 'discharge', 'his', 'left', 'history', 'am', 'her', 'were', 'you', 'right', 'by', 'your', 'not', 'pm', 'be', 'had', 'pt', 'pain', 'this', 'q', 'from', 'p', 'that', 'an']\n",
    "stopwords_remover = StopWordsRemover()\\\n",
    "                    .setInputCol('tokens')\\\n",
    "                    .setOutputCol('filtered_words')\\\n",
    "                    .setStopWords(extra_stopwords)\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=1000, minCount=10)\\\n",
    "           .setInputCol(\"filtered_words\")\\\n",
    "           .setOutputCol(\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEydLpnGCnS3",
    "outputId": "1b1c4fc4-8e3b-4c9c-e628-c6310f0a796b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.665\n",
      "AUCPR: 0.644\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 8007|\n",
      "|  0.0|       1.0| 4960|\n",
      "|  1.0|       0.0| 4968|\n",
      "|  0.0|       0.0| 8141|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.617\n",
      "recall: 0.617\n",
      "accuracy: 0.619\n",
      "F1 score: 0.617\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.625\n",
      "AUCPR: 0.629\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  896|\n",
      "|  0.0|       1.0|  543|\n",
      "|  1.0|       0.0|  660|\n",
      "|  0.0|       0.0|  850|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.623\n",
      "recall: 0.576\n",
      "accuracy: 0.592\n",
      "F1 score: 0.598\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.634\n",
      "AUCPR: 0.637\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  942|\n",
      "|  0.0|       1.0|  565|\n",
      "|  1.0|       0.0|  634|\n",
      "|  0.0|       0.0|  867|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.625\n",
      "recall: 0.598\n",
      "accuracy: 0.601\n",
      "F1 score: 0.611\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# label_string_idx = StringIndexer(inputCol = 'Label', outputCol = \"label\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.0001)\n",
    "# pipeline_wv_lr = Pipeline().setStages([word2Vec, label_string_idx, lr])\n",
    "pipeline_wv = Pipeline().setStages([regex_tokenizer, stopwords_remover, word2Vec])\n",
    "wvtoken = pipeline_wv.fit(train_set)\n",
    "wvmodel = get_pred(wvtoken, 'Label', lr, train_set, val_set, test_set )\n",
    "\n",
    "# pipeline_wv_lr = Pipeline().setStages([wvtoken, label_string_idx, lr])\n",
    "# model_wv_lr = pipeline_wv_lr.fit(train_set)\n",
    "# predictions_wv_lr = model_wv_lr.transform(test_set)\n",
    "# # take 8 min with vectorsize 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIHguBZZh4JR",
    "outputId": "f68b70d4-3038-4b07-e44a-004aa64d783c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 1.000\n",
      "AUCPR: 1.000\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|12975|\n",
      "|  0.0|       0.0|13101|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 1.000\n",
      "recall: 1.000\n",
      "accuracy: 1.000\n",
      "F1 score: 1.000\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.618\n",
      "AUCPR: 0.625\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  894|\n",
      "|  0.0|       1.0|  574|\n",
      "|  1.0|       0.0|  662|\n",
      "|  0.0|       0.0|  819|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.609\n",
      "recall: 0.575\n",
      "accuracy: 0.581\n",
      "F1 score: 0.591\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.613\n",
      "AUCPR: 0.613\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  939|\n",
      "|  0.0|       1.0|  616|\n",
      "|  1.0|       0.0|  637|\n",
      "|  0.0|       0.0|  816|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.604\n",
      "recall: 0.596\n",
      "accuracy: 0.583\n",
      "F1 score: 0.600\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier( numTrees=100, maxDepth=20, subsamplingRate=0.88)\n",
    "wvmodel_rf = get_pred(wvtoken, 'Label', rf, train_set, val_set, test_set )\n",
    "# take 14mins to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxWBst_o5ncJ"
   },
   "source": [
    "#### reduce maxSentenceLength from default 1000 to 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fSydtJehOi9",
    "outputId": "7d5f12ce-bb01-47eb-bf0a-65a1227977c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.662\n",
      "AUCPR: 0.642\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 7876|\n",
      "|  0.0|       1.0| 4851|\n",
      "|  1.0|       0.0| 5099|\n",
      "|  0.0|       0.0| 8250|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.619\n",
      "recall: 0.607\n",
      "accuracy: 0.618\n",
      "F1 score: 0.613\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.625\n",
      "AUCPR: 0.630\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  859|\n",
      "|  0.0|       1.0|  512|\n",
      "|  1.0|       0.0|  697|\n",
      "|  0.0|       0.0|  881|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.627\n",
      "recall: 0.552\n",
      "accuracy: 0.590\n",
      "F1 score: 0.587\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.636\n",
      "AUCPR: 0.637\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  931|\n",
      "|  0.0|       1.0|  546|\n",
      "|  1.0|       0.0|  645|\n",
      "|  0.0|       0.0|  886|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.630\n",
      "recall: 0.591\n",
      "accuracy: 0.604\n",
      "F1 score: 0.610\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2Vec1 = Word2Vec(vectorSize=1000, minCount=10, maxSentenceLength=512)\\\n",
    "           .setInputCol(\"filtered_words\")\\\n",
    "           .setOutputCol(\"features\")\n",
    "           \n",
    "# default Word2Vec(*, vectorSize=100, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, seed=None, inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.0001)\n",
    "pipeline_wv1 = Pipeline().setStages([regex_tokenizer, stopwords_remover, word2Vec1])\n",
    "wvtoken1 = pipeline_wv1.fit(train_set)\n",
    "wvmodel1 = get_pred(wvtoken1, 'Label', lr, train_set, val_set, test_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1KQVxL2rn2n",
    "outputId": "910157f1-f46f-4558-ba83-3d7aba6119a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.657\n",
      "AUCPR: 0.635\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 8165|\n",
      "|  0.0|       1.0| 5214|\n",
      "|  1.0|       0.0| 4810|\n",
      "|  0.0|       0.0| 7887|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.610\n",
      "recall: 0.629\n",
      "accuracy: 0.616\n",
      "F1 score: 0.620\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.623\n",
      "AUCPR: 0.629\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  911|\n",
      "|  0.0|       1.0|  577|\n",
      "|  1.0|       0.0|  645|\n",
      "|  0.0|       0.0|  816|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.612\n",
      "recall: 0.585\n",
      "accuracy: 0.586\n",
      "F1 score: 0.599\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.629\n",
      "AUCPR: 0.629\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  974|\n",
      "|  0.0|       1.0|  587|\n",
      "|  1.0|       0.0|  602|\n",
      "|  0.0|       0.0|  845|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.624\n",
      "recall: 0.618\n",
      "accuracy: 0.605\n",
      "F1 score: 0.621\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(maxIter=10, regParam=0.005, elasticNetParam=0.5)\n",
    "wvmodel2 = get_pred(wvtoken1, 'Label', lr1, train_set, val_set, test_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkwm9Mkvk9pN",
    "outputId": "a1f76e5c-d1bb-4e58-d4b4-89063658fe32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.922\n",
      "AUCPR: 0.921\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|11141|\n",
      "|  0.0|       1.0| 2347|\n",
      "|  1.0|       0.0| 1834|\n",
      "|  0.0|       0.0|10754|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.826\n",
      "recall: 0.859\n",
      "accuracy: 0.840\n",
      "F1 score: 0.842\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.610\n",
      "AUCPR: 0.618\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  863|\n",
      "|  0.0|       1.0|  584|\n",
      "|  1.0|       0.0|  693|\n",
      "|  0.0|       0.0|  809|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.596\n",
      "recall: 0.555\n",
      "accuracy: 0.567\n",
      "F1 score: 0.575\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.620\n",
      "AUCPR: 0.624\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  947|\n",
      "|  0.0|       1.0|  601|\n",
      "|  1.0|       0.0|  629|\n",
      "|  0.0|       0.0|  831|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.612\n",
      "recall: 0.601\n",
      "accuracy: 0.591\n",
      "F1 score: 0.606\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(numTrees=50, maxDepth=10)\n",
    "wvmodel_rf1 = get_pred(wvtoken1, 'Label', rf1, train_set, val_set, test_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXRBpIlSujx0",
    "outputId": "faf62f12-cf69-4deb-99d7-b2d6bb37640f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 1.000\n",
      "AUCPR: 1.000\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|12974|\n",
      "|  0.0|       1.0|    1|\n",
      "|  1.0|       0.0|    1|\n",
      "|  0.0|       0.0|13100|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 1.000\n",
      "recall: 1.000\n",
      "accuracy: 1.000\n",
      "F1 score: 1.000\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.606\n",
      "AUCPR: 0.615\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  866|\n",
      "|  0.0|       1.0|  566|\n",
      "|  1.0|       0.0|  690|\n",
      "|  0.0|       0.0|  827|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.605\n",
      "recall: 0.557\n",
      "accuracy: 0.574\n",
      "F1 score: 0.580\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.609\n",
      "AUCPR: 0.616\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  931|\n",
      "|  0.0|       1.0|  619|\n",
      "|  1.0|       0.0|  645|\n",
      "|  0.0|       0.0|  813|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.601\n",
      "recall: 0.591\n",
      "accuracy: 0.580\n",
      "F1 score: 0.596\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(numTrees=50, maxDepth=20)\n",
    "wvmodel_rf2 = get_pred(wvtoken1, 'Label', rf2, train_set, val_set, test_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DV11_g4A51TL"
   },
   "source": [
    "#### reduce maxSentenceLength from default 1000 to 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s01VuYMfwC7K",
    "outputId": "9d7baa62-47f3-45c0-beee-58b03a8c0e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set metric\n",
      "AUROC: 0.665\n",
      "AUCPR: 0.644\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 8024|\n",
      "|  0.0|       1.0| 4945|\n",
      "|  1.0|       0.0| 4951|\n",
      "|  0.0|       0.0| 8156|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.619\n",
      "recall: 0.618\n",
      "accuracy: 0.620\n",
      "F1 score: 0.619\n",
      "\n",
      "\n",
      "val set metric\n",
      "AUROC: 0.628\n",
      "AUCPR: 0.633\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  899|\n",
      "|  0.0|       1.0|  536|\n",
      "|  1.0|       0.0|  657|\n",
      "|  0.0|       0.0|  857|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.626\n",
      "recall: 0.578\n",
      "accuracy: 0.595\n",
      "F1 score: 0.601\n",
      "\n",
      "\n",
      "test set metric\n",
      "AUROC: 0.632\n",
      "AUCPR: 0.636\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  931|\n",
      "|  0.0|       1.0|  577|\n",
      "|  1.0|       0.0|  645|\n",
      "|  0.0|       0.0|  855|\n",
      "+-----+----------+-----+\n",
      "\n",
      "precision: 0.617\n",
      "recall: 0.591\n",
      "accuracy: 0.594\n",
      "F1 score: 0.604\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2Vec2 = Word2Vec(vectorSize=1000, minCount=10, maxSentenceLength=320)\\\n",
    "           .setInputCol(\"filtered_words\")\\\n",
    "           .setOutputCol(\"features\")\n",
    "           \n",
    "# default Word2Vec(*, vectorSize=100, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, seed=None, inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000\n",
    "pipeline_wv2 = Pipeline().setStages([regex_tokenizer, stopwords_remover, word2Vec2])\n",
    "\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.0001)\n",
    "wvtoken2 = pipeline_wv2.fit(train_set)\n",
    "wvmodel2 = get_pred(wvtoken2, 'Label', lr, train_set, val_set, test_set )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SMVSSmKo8BUr",
    "FIz2m_eR8KnB",
    "z0btCbCb61pM",
    "y_YHTzK-4lCy",
    "9i1N0YjcF8Mx",
    "am29d1YSGE11",
    "0VfDa-UuEw3m",
    "0U-0QAjy5Aid",
    "FFz50O8u5RKx",
    "kxWBst_o5ncJ",
    "DV11_g4A51TL",
    "0JvUqfP70JPi"
   ],
   "machine_shape": "hm",
   "name": "revise re-admit30-prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
